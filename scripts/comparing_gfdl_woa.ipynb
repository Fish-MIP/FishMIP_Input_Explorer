{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9a0b1d6-bb0d-4030-bc0c-7ed2534c4b00",
   "metadata": {},
   "source": [
    "# Calculating differences between World Ocean Atlas 2023 and GFDL-MOM6-COBALT2 model outputs\n",
    "**Author:** Denisse Fierro Arcos  \n",
    "**Date:** 2024-10-03  \n",
    "  \n",
    "We use the original GFDL-MOM6-COBALT2 model outputs for ocean temperature (`thetao`) and salinity (`so`) to calculate a climatology mean matching the period covered by World Ocean Atlas 2023 (WOA23): 1981-2010. These climatologies are saved as `zarr` files for use in the future.\n",
    "\n",
    "We calculate the following:\n",
    "- GFDL outputs are substracted from WOA23 data\n",
    "- Percentage difference betwen GFDL and WOA23 data\n",
    "\n",
    "Both products are saved as `parquet` files at a global scale, and data is also extracted and saved for each FishMIP regional model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8721b482-cefe-4e3f-9394-fbf524607183",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import os\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from dask.distributed import Client\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6d647c-567c-4d45-b736-f2263a1c8cc7",
   "metadata": {},
   "source": [
    "## Starting a cluster\n",
    "This will allow us to automatically parallelising tasks on large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d56e7f29-4751-45cf-abbc-d4fc512ac2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(threads_per_worker = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42788e3b-a53e-4e6f-be9d-beb2b6bc03b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = '/g/data/vf71/fishmip_inputs/ISIMIP3a/global_inputs/obsclim/025deg'\n",
    "out_folder = os.path.join(base_folder, 'comp_clim_woa')\n",
    "os.makedirs(out_folder, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dda14f2-ced6-47ff-aa87-017b1b29de55",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Defining function calculating climatology from WOA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b414a14c-ef86-4be8-8090-62e1cc51cbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gfdl_match_woa(file_path, file_out, monthly = False):\n",
    "    '''\n",
    "    Inputs:\n",
    "    file_path (character): Full file path where original GFDL netCDF file is stored.\n",
    "    file_out (character): Full file path where climatology will be stored.\n",
    "    monthly (boolean). Default is False. If set to True, then monthly climatologies \n",
    "    are calculated.\n",
    "\n",
    "    Outputs:\n",
    "    da (data array): Climatological mean matching WOA period: 1981-2010\n",
    "    '''\n",
    "    da = xr.open_dataarray(file_path)\n",
    "    \n",
    "    #Select same period as WOA data\n",
    "    da = da.sel(time = slice('1981', '2010'))\n",
    "    \n",
    "    #Rechunk data and rename depth variable to match WOA data\n",
    "    da = da.chunk({'lat': 144, 'lon': 288}).rename({'lev': 'depth'})\n",
    "    \n",
    "    #Calculate climatology mean\n",
    "    if monthly:\n",
    "        da = da.groupby('time.month').mean('time')\n",
    "    else:\n",
    "        da = da.mean('time')\n",
    "    \n",
    "    #Save results as zarr file\n",
    "    da.to_zarr(file_out, consolidated = True, mode = 'w')\n",
    "\n",
    "    return da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7e0903-c117-4f02-b8f6-867f6f4d56d4",
   "metadata": {},
   "source": [
    "## Defining location of original GFDL files and output paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b15748e4-d976-4d34-a787-a6054b5830b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Temperature files\n",
    "gfdl_temp_file = os.path.join(\n",
    "    base_folder, 'gfdl-mom6-cobalt2_obsclim_thetao_15arcmin_global_monthly_1961_2010.nc')\n",
    "gfdl_out_temp = os.path.join(\n",
    "    out_folder,  'gfdl-mom6-cobalt2_obsclim_global_clim_mean_temp_1981_2010.zarr')\n",
    "\n",
    "#Salinity files\n",
    "gfdl_sal_file = os.path.join(\n",
    "    base_folder, 'gfdl-mom6-cobalt2_obsclim_so_15arcmin_global_monthly_1961_2010.nc')\n",
    "gfdl_out_sal = os.path.join(\n",
    "    out_folder, 'gfdl-mom6-cobalt2_obsclim_global_clim_mean_sal_1981_2010.zarr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e65b81-68d9-4665-b535-e7c32c83f0bc",
   "metadata": {},
   "source": [
    "## Applying function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a3784e5-1233-4b3e-9131-26e61b867707",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gfdl_temp = gfdl_match_woa(gfdl_temp_file, gfdl_out_temp)\n",
    "gfdl_sal = gfdl_match_woa(gfdl_sal_file, gfdl_out_sal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87c93f4-e506-4ab8-9d25-0cca04f0b5be",
   "metadata": {},
   "source": [
    "## *Optional: Loading GFDL climatologies matching WOA period*\n",
    "If climatologies were already calculated, you can upload them using the chunk below instead of recalculating them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dcb27b9-384c-4a88-82a2-5fcb0ec2d001",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gfdl_temp = xr.open_zarr(gfdl_out_temp).thetao\n",
    "gfdl_sal = xr.open_zarr(gfdl_out_sal).so"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9611f7bc-6a7b-4981-b167-2360e92e1de9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Loading regridded World Ocean Atlas (WOA)\n",
    "This step was performed in the `regridding_woa_data.ipynb` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eabdf9c8-0b60-4ecd-83b5-e6432813b54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_woa = '/g/data/vf71/WOA_data/global'\n",
    "temp_woa = xr.open_zarr(\n",
    "    os.path.join(base_woa, \n",
    "                 'regridded_woa_clim_mean_temp_1981-2010.zarr')).temperature\n",
    "salt_woa = xr.open_zarr(\n",
    "    os.path.join(base_woa, \n",
    "                 'regridded_woa_clim_mean_sal_1981-2010.zarr')).salinity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfbd853-7daf-4797-816f-49dd9dd5a3bd",
   "metadata": {},
   "source": [
    "## Calculating difference between GFDL and WOA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bcf67a5-f572-4bab-88f0-8efae0c58b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_temp = gfdl_temp-temp_woa\n",
    "per_diff_temp = (diff_temp/temp_woa)*100\n",
    "\n",
    "diff_sal = gfdl_sal-salt_woa\n",
    "per_diff_sal = (diff_sal/salt_woa)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fe9651-3243-48c0-a405-8aa15aed0282",
   "metadata": {},
   "source": [
    "## Loading FishMIP regions mask and shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d665795-9d60-49c0-9f10-5bdfa07340d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define folder with shared resources\n",
    "shared_res = '/g/data/vf71/shared_resources'\n",
    "# Loading shapefile\n",
    "rmes = gpd.read_file(\n",
    "    os.path.join(shared_res, 'FishMIP_regional_models/FishMIP_regional_models.shp'))\n",
    "\n",
    "# Loading mask\n",
    "mask_ras = xr.open_dataset(\n",
    "    os.path.join(shared_res, \n",
    "                 'FishMIPMasks/merged_regional_fishmip',\n",
    "                 'gfdl-mom6-cobalt2_areacello_15arcmin_fishMIP_regional_merged.nc')).region\n",
    "#Renaming coordinate dimensions\n",
    "mask_ras = mask_ras.rename({'latitude': 'lat', 'longitude': 'lon'})\n",
    "#Rechunking data to make it more manageable\n",
    "mask_ras = mask_ras.chunk({'lat': 144, 'lon': 288})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84a1e8a-2787-4e4d-9fda-86f991e307a2",
   "metadata": {},
   "source": [
    "## Defining functions to mask and extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "083cbbf9-7efa-40db-8b1d-809586855b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_data(da, mask):\n",
    "    '''\n",
    "    Open netCDF files in analysis ready data (ARD) format. That is apply chunks\n",
    "    that make data analysis easier.\n",
    "    \n",
    "    Inputs:\n",
    "    da (data array): Data array containing data to be extracted\n",
    "    mask_ras (boolean data array): Data array to be used as initial mask\n",
    "    to decrease the size of the original dataset. This mask makes no distinction\n",
    "    between regional models, it simply identifies grid cells within regional \n",
    "    model boundaries with the value of 1.\n",
    "    \n",
    "    Outputs:\n",
    "    da (data array): ARD data array containing data only for grid cells within\n",
    "    regional model boundaries.\n",
    "    '''\n",
    "    \n",
    "    da_mask = da.where(mask == 1)\n",
    "    da_mask.rio.set_spatial_dims(x_dim = 'lon', y_dim = 'lat', inplace = True)\n",
    "    da_mask.rio.write_crs('epsg:4326', inplace = True)\n",
    "    da_mask = da_mask.chunk({'lat': 144, 'lon': 288})\n",
    "    return da_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "42355599-ac47-48b6-86f3-0a7e3395632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_data(da, region, file_out):\n",
    "    '''\n",
    "    Open netCDF files in analysis ready data (ARD) format. That is apply chunks\n",
    "    that make data analysis easier.\n",
    "    \n",
    "    Inputs:\n",
    "    da (data array): Data array containing data to be extracted\n",
    "    region (shapefile): Shapefile containing the boundaries of regional models\n",
    "    file_out (character): Full file path where masked data should be stored.\n",
    "    \n",
    "    Outputs:\n",
    "    No data is returned, but masked file will be stored in specified file path.\n",
    "    '''\n",
    "    #Clip data using regional shapefile\n",
    "    da_mask = da.rio.clip(region.geometry, region.crs, drop = True, \n",
    "                          all_touched = True)\n",
    "    #Remove spatial information\n",
    "    da_mask = da_mask.drop_vars('spatial_ref')\n",
    "    da_mask.encoding = {}\n",
    "\n",
    "    #Keep data array attributes to be recorded in final data frame\n",
    "    da_attrs = da.attrs\n",
    "    da_attrs = pd.DataFrame([da_attrs])\n",
    "    #Set column order\n",
    "    if 'month' in list(da_mask.coords):\n",
    "        ind_wider = ['lat', 'lon', 'month', 'depth', 'vals']\n",
    "    else:\n",
    "        ind_wider = ['lat', 'lon', 'depth', 'vals']\n",
    "    #Turn extracted data into data frame and remove rows with NA values\n",
    "    df = da_mask.to_series().to_frame().reset_index().dropna()\n",
    "    #Changing column name to standardise across variables\n",
    "    df = df.rename(columns = {da.name: 'vals'}).reset_index(drop = True)\n",
    "    #Reorganise data\n",
    "    df = df[ind_wider]\n",
    "    #Include original dataset attributes\n",
    "    df = pd.concat([df, da_attrs], axis = 1)\n",
    "    #Saving data frame\n",
    "    df.to_parquet(file_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8864dc39-3368-46b4-9e04-e963e879b984",
   "metadata": {},
   "source": [
    "## Extracting regridded WOA data for each region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "913b037a-87bb-4f13-984e-e33dfe2baee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_out = '/g/data/vf71/fishmip_inputs/ISIMIP3a/regional_inputs/obsclim/025deg/comp_maps'\n",
    "os.makedirs(base_out, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be6b2323-f4dd-495f-bd4f-a10f182d47f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_temp_masked = mask_data(diff_temp, mask_ras)\n",
    "diff_temp_masked.name = 'temperature'\n",
    "\n",
    "per_diff_temp_masked = mask_data(per_diff_temp, mask_ras)\n",
    "per_diff_temp_masked.name = 'temperature'\n",
    "\n",
    "for i in rmes.region:\n",
    "    #Get polygon for each region\n",
    "    mask = rmes[rmes.region == i]\n",
    "    #Get name of region and clean it for use in output file\n",
    "    reg_name = mask['region'].values[0].lower().replace(\" \", \"-\").replace(\"'\", \"\")\n",
    "    #File name out - Replacing \"global\" for region name\n",
    "    file_out_diff = f'diff_gfdl-woa_{reg_name}_temp_1981-2010.parquet'\n",
    "    file_out_per_diff = f'per_diff_gfdl-woa_{reg_name}_temp_1981-2010.parquet'\n",
    "    clip_data(diff_temp_masked, mask, os.path.join(base_out, file_out_diff))\n",
    "    clip_data(per_diff_temp_masked, mask, os.path.join(base_out, file_out_per_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "522c0427-4b43-407f-a04e-515f1ca37527",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_sal_masked = mask_data(diff_sal, mask_ras)\n",
    "diff_sal_masked.name = 'salinity'\n",
    "\n",
    "per_diff_sal_masked = mask_data(per_diff_sal, mask_ras)\n",
    "per_diff_sal_masked.name = 'salinity'\n",
    "\n",
    "for i in rmes.region:\n",
    "    #Get polygon for each region\n",
    "    mask = rmes[rmes.region == i]\n",
    "    #Get name of region and clean it for use in output file\n",
    "    reg_name = mask['region'].values[0].lower().replace(\" \", \"-\").replace(\"'\", \"\")\n",
    "    #File name out - Replacing \"global\" for region name\n",
    "    file_out_diff = f'diff_gfdl-woa_{reg_name}_sal_1981-2010.parquet'\n",
    "    file_out_per_diff = f'per_diff_gfdl-woa_{reg_name}_sal_1981-2010.parquet'\n",
    "    clip_data(diff_sal_masked, mask, os.path.join(base_out, file_out_diff))\n",
    "    clip_data(per_diff_sal_masked, mask, os.path.join(base_out, file_out_per_diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6039f481-98dd-4f40-822b-13c4744f7ace",
   "metadata": {},
   "source": [
    "## Defining location of monthly output paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48f23696-521d-4d77-8169-14a5c17bf140",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Temperature files\n",
    "gfdl_out_temp_month = os.path.join(\n",
    "    out_folder,  'gfdl-mom6-cobalt2_obsclim_global_monthly_clim_mean_temp_1981_2010.zarr')\n",
    "\n",
    "#Salinity files\n",
    "gfdl_out_sal_month = os.path.join(\n",
    "    out_folder, 'gfdl-mom6-cobalt2_obsclim_global_monthly_clim_mean_sal_1981_2010.zarr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded6964d-be53-4249-9c59-26d86cc9db85",
   "metadata": {},
   "source": [
    "## Applying function\n",
    "This only needs to be done once for the entire globe. If new FishMIP models are submitted, data can be loaded in the next chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c6ebfd0-44db-4e6b-a338-1b172d5f8ff8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flox:Entering _validate_reindex: reindex is None\n",
      "INFO:flox:Leaving _validate_reindex: method = None, returning None\n",
      "INFO:flox:_choose_engine: Choosing 'numpy'\n",
      "INFO:flox:_choose_method: method is None\n",
      "INFO:flox:_choose_method: choosing preferred_method=blockwise\n",
      "INFO:flox:Entering _validate_reindex: reindex is None\n",
      "INFO:flox:Leaving _validate_reindex: reindex is False\n"
     ]
    }
   ],
   "source": [
    "gfdl_temp_month = gfdl_match_woa(gfdl_temp_file, gfdl_out_temp_month, \n",
    "                                 monthly = True)\n",
    "gfdl_sal_month = gfdl_match_woa(gfdl_sal_file, gfdl_out_sal_month,\n",
    "                                monthly = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f53e4cd-5162-4eb7-ac82-a2fd2f259554",
   "metadata": {},
   "source": [
    "## *If monthly climatologies were calculated*: Load monthly climatologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0fabe0d6-5352-4c4a-9d75-34b733604348",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Masking temperature and salinity monthly climatologies\n",
    "gfdl_temp_month = xr.open_zarr(gfdl_out_temp_month).thetao\n",
    "gfdl_temp_month_masked = mask_data(gfdl_temp_month, mask_ras)\n",
    "\n",
    "gfdl_sal_month = xr.open_zarr(gfdl_out_sal_month).so\n",
    "gfdl_sal_month_masked = mask_data(gfdl_sal_month, mask_ras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d7de0a0d-c8b8-48b1-bd44-93d6531bef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Location of folder where monthly climatology per region will be stored\n",
    "folder_out = os.path.join('/g/data/vf71/fishmip_inputs/ISIMIP3a/regional_inputs',\n",
    "                          'obsclim/025deg/monthly_clim_corr')\n",
    "\n",
    "for i in rmes.region:\n",
    "    #Get polygon for each region\n",
    "    mask = rmes[rmes.region == i]\n",
    "    #Get name of region and clean it for use in output file\n",
    "    reg_name = mask['region'].values[0].lower().replace(\" \", \"-\").replace(\"'\", \"\")\n",
    "    #File name out - Replacing \"global\" for region name\n",
    "    file_out_temp = f'gfdl-mom6-cobalt2_obsclim_thetao_15arcmin_{reg_name}_mthly_clim_mean_1981_2010.parquet'\n",
    "    file_out_sal = f'gfdl-mom6-cobalt2_obsclim_so_15arcmin_{reg_name}_mthly_clim_mean_1981_2010.parquet'\n",
    "    clip_data(gfdl_temp_month_masked, mask, \n",
    "              os.path.join(folder_out, file_out_temp))\n",
    "    clip_data(gfdl_sal_month_masked, mask, \n",
    "              os.path.join(folder_out, file_out_sal))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis3-24.04] *",
   "language": "python",
   "name": "conda-env-analysis3-24.04-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
